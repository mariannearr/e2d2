<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="BD3-LMs">
  <meta name="twitter:description" content="BD3-LMs">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="encoder-decoder diffusion, encoder-decoder discrete diffusion, discrete, masked, diffusion, language models, E2D2, masked diffusion">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Encoder-Decoder Diffusion</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>

</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop-wide">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-3 publication-title">Encoder-Decoder Diffusion Language Models for Efficient Training and Inference</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block"><a href="https://m-arriola.com/" target="_blank">Marianne Arriola</a><sup>*</sup>,</span>
                <span class="author-block"><a href="https://yair-schiff.github.io" target="_blank">Yair Schiff</a><sup>*</sup>,</span>
                  <span class="author-block"><a href="https://hao-pt.github.io" target="_blank">Hao Phung</a>,</span>
                  <span class="author-block"><a href="https://skylion007.github.io/" target="_blank">Aaron Gokaslan Yang</a>,</span>
                  <span class="author-block"><a href="https://www.cs.cornell.edu/~kuleshov/" target="_blank">Volodymyr Kuleshov</a></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Cornell Tech. <sup>*</sup>Equal contribution; corresponding authors</span> 
            </div>

            <div class="is-size-6 publication-flag" style="padding-top: 20px; padding-bottom: 20px;">
              <b>NeurIPS 2025</b>
            </div>

            <div class="link-buttons">
              <a href="https://openreview.net/forum?id=5jneOToPou&referrer=%5Bthe%20profile%20of%20Marianne%20Arriola%5D(%2Fprofile%3Fid%3D~Marianne_Arriola1)" target="_blank"
                class="button link-chip">
                <span class="icon"><i class="fas fa-file"></i></span>
                <span>Paper</span>
              </a>

              <a href="https://github.com/kuleshov-group/e2d2" target="_blank"
                class="button link-chip">
                <span class="icon"><i class="fab fa-github"></i></span>
                <span>Code</span>
              </a>

              <a href="https://huggingface.co/collections/kuleshov-group/e2d2" target="_blank"
                class="button link-chip">
                <span class="icon">
                  <img src="static/images/hf.png" alt="Hugging Face" class="hf-icon">
                </span>
                <span>HuggingFace</span>
              </a>
            </div>
                          
        </div>
      </div>
    </div>
</section>


<!-- Teaser video-->
<section class="hero teaser is-max-desktop">
  <div class="container">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        <span style="color: #d32f2f">Slow, decoder-only diffusion.</span><br>
         <span class="legend-box border-3-solid"><b>Large decoder</b> denoises tokens & caches clean context</span>
      </h2>
      <hr style="
        border: none;
        border-top: 1px solid #e0e0e0;
        width: 80%;
        margin: 0.1rem auto 1rem auto;
      ">
      <img src="static/images/bd3lm.gif" style="padding-bottom: 60px; width:80%;">

      <h2 class="subtitle has-text-centered" style="padding-top: 20px;">
        <span style="color: #2e7d32;">Fast, encoder-decoder diffusion.</span><br>
         <span class="legend-box border-1-dotted"><b>Small decoder</b> denoises tokens</span> <span class="legend-box border-1-solid"><b>Large encoder</b> caches clean context</span>
      </h2>
      <hr style="
        border: none;
        border-top: 1px solid #e0e0e0;
        width: 80%;
        margin: 0.1rem auto 1rem auto;
      ">
      <img src="static/images/e2d2.gif" style="padding-bottom: 20px; width:80%;">
      </div>
  </div>
</section> 



<!-- BD3-LMs -->
<style>
/* Compact, clean link chips */
      .title.publication-title {
        margin-bottom: 0.35rem !important;  /* default is ~1–1.5rem */
        line-height: 1.15;                  /* reduces perceived vertical space */
      }
      .publication-flag {
        padding-top: 8px !important; /* reduce vertical space below NeurIPS 2025 */
        padding-bottom: 8px !important; /* reduce vertical space below NeurIPS 2025 */
      }
      
    
      .link-buttons{
        display:flex;
        gap:.2rem;
        justify-content:center;
        align-items:center;
        flex-wrap:wrap;
        margin-top:.25rem;
      }

      .link-chip{
        /* base */
        height:auto;                 /* let padding control height */
        line-height:1.1;
        font-size:.8rem;             /* slightly smaller */
        font-weight:500;
        padding:.15rem .7rem;        /* thinner */
        border-radius:9999px;        /* pill */
        border:1px solid #e0e0e0;    /* thin outline */
        color:#fff;             /* ghost look on light bg */
        background:#111;
        box-shadow:none;
      }

      .link-chip .icon i{
        font-size:.95em;
      }

      /* HF raster icon size */
      .hf-icon{
        width:16px;
        height:16px;
        display:block;
      }

      /* Hover/focus states */
      .link-chip:hover{
        border-color:#bdbdbd;
        background:#fafafa;
      }

      .link-chip:focus{
        outline:2px solid #8ab4f8;   /* accessible focus ring */
        outline-offset:2px;
      }

      .hero:not(.teaser) .hero-body {
          padding-bottom: 0.75rem;  /* was ~3rem */
        }

        /* Reduce space above the teaser hero */
        .hero.teaser .hero-body {
          padding-top: 0.75rem;     /* was ~3rem */
        }


      .legend-box {
        border-radius: 6px;
        padding: 2px 4px;
        display: inline-block;
        min-width: 100px;
        text-align: center;
        color: rgb(52, 87, 112); /* same text color as your code */
        margin: 4px;
        font-size: 0.8em;
      }
      .no-border { border: none; }
      .border-3-solid { border: 3px solid #000; }
      .border-1-solid { border: 1px solid #000; }
      .border-1-dotted { border: 1px dotted #000; }

      .container.is-max-desktop {
          max-width: 50%; /* Increase the width */
          width: 50%;
      }
      .container.is-max-desktop-wide {
          max-width: 65%; /* Increase the width */
          width: 65%;
      }
      .section {
            padding-left: 5%;
            padding-right: 5%;
        }
      .hero-body {
        display: flex;
        flex-direction: column;   /* keeps elements stacked vertically */
        justify-content: center;  /* vertical centering */
        align-items: center;      /* horizontal centering */
        text-align: center;       /* keep text centered inside child elements */
      }
      
      .subtitle.has-text-centered {
          font-size: 1.3em; /* Increase font size */
      }

        p {
          font-size: 18px;
        }

        .author-block {
          font-size: 18px;
        }
      

        .figure-caption-container {
            display: flex;
            flex-direction: column; /* Captions and figure container are in a vertical stack */
            align-items: center;
            gap: 20px; /* Spacing between figure and color captions */
        }

        .figure-content-container {
            display: flex;
            flex-direction: row; /* Figure and color boxes are side by side */
            align-items: center;
            gap: 20px;
        }

        .figure-container {
            flex-shrink: 0; /* Prevents figure from shrinking */
        }

        .captions {
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: flex-start;
        }

        .caption {
            display: flex;
            align-items: center;
            margin-bottom: 10px;
            font-size: 16px;
        }
      /* Reduce top margin between second figure and text */
      #SEC2 .hero.is-small {
        margin-top: 0rem !important;   /* reduce space above the figure */
      }

      #SEC2 .hero.is-small .hero-body {
        padding-top: 0.25rem !important;  /* reduce padding inside the figure section */
      }
      /* Space AROUND the tables */
      table {
        margin: 2rem auto;           /* more room above/below + centered */
      }

  .color-box {
      display: inline-block;
      width: 20px;
      height: 20px;
      margin-right: 5px;
      vertical-align: middle;
  }
  .orange { background-color: #ff9900; }
  .light-orange { background-color: #FFDAB9; }
  .blue { background-color: #30beee; }
  .dark-green { background-color: #006400; }
  .green { background-color: #228B22; }
  .light-green { background-color: #90EE90; }
</style>



<section class="section" id="SEC2">
  <div class="container is-max-desktop">
    <div class="content is-medium">
      <p>To generate samples, diffusion models iteratively refine a sequence consisting of both clean and corrupted tokens. Our key insight is that this process consists of: 1) producing useful representations of clean tokens and 2) denoising corrupted tokens.</p>

      <p>However, prior diffusion language models jointly perform both tasks within the same decoder-only architecture. Thus, these models must expensively invoke the full network at every denoising step.</p>

      <p>We propose an encoder-decoder transformer architecture to separate the computation for these tasks. We use an encoder to represent clean tokens and a lightweight decoder to iteratively refine a noised sequence conditioned on the encoder’s representation. This enables faster inference, as we call the lightweight decoder multiple times to iteratively denoise tokens and invoke the encoder only periodically to update its representations.</p>
      
      <p>Our <b>E</b>fficient <b>E</b>ncoder-<b>D</b>ecoder <b>D</b>iffusion (E2D2) consists of an encoder-decoder transformer architecture complemented with efficient training and sampling algorithms that enable both faster inference and KV caching support.</p>
      <section class="hero is-small">
        <div class="hero-body">
        <img src="static/images/graphical_abstract.png" alt="mask" style="width:100%; padding-bottom: 10px;">
        <div class="figure-caption" style="padding-bottom: 10px; font-size:16px">
          <i>Efficient Encoder-Decoder Diffusion (E2D2) enables faster generation than decoder-only architectures.</i>
      </div>
        </div>
      </section>
      <p>Our encoder-decoder architecture enables faster training of block diffusion models, which partition sequences into blocks to improve generation quality and support KV caching. Block diffusion is widely used for generating with large diffusion language models, even those trained with standard full-sequence diffusion (e.g., LLaDA, Seed Diffusion, MMaDA). 
        
      <p>However, decoder-only block diffusion incurs higher training costs, with forward passes that are 2× more expensive than standard diffusion, as both the full clean and noised sequences must be processed in every transformer layer.</p>
      
      <p>Encoder-decoder block diffusion uses the encoder to process the clean sequence and the decoder to process the noised sequence, halving training costs compared to a decoder-only model of equal size. During inference, the decoder generates each block of tokens, then the encoder caches their KVs.</p>
    </div>
  </div>
</section>


<!-- RESULTS -->
<section class="section" id="SEC2">
  <div class="container is-max-desktop content">
    <div class="content is-medium">
      <h2 class="title">Results</h2>
        <p>
          We focus on applying the encoder-decoder architecture to parameterizing block diffusion as it attains superior language modeling performance compared to full-sequence masked diffusion, it enables exact KV caching for faster inference, and even recent diffusio LLMs which are trained with the full-sequence masked diffusion parameterization apply on block autoregressive decoding at inference.
        </p>
        <p>
          By varying the depth of E2D2’s decoder and that of decoder-only block diffusion (BD3LM), we examine the trade-off between performance and throughput. We fine-tune models for mathematical reasoning on the GSM8K dataset and compute 0-shot pass@1 accuracy and decoding throughput. E2D2 extends the Pareto frontier of quality and speed as shown below.
        </p>
        <section class="hero is-small">
        <div class="hero-body">
        <img src="static/images/pareto_frontier.png" alt="mask" style="width:70%; padding-bottom: 10px;">
        <div class="figure-caption" style="padding-bottom: 10px; font-size:16px;">
          <i>Mapping the Pareto Frontier: Larger models increase accuracy on GSM8K at the cost of slower decoding.</i>
      </div>
        </div>
      </section>
      <p>
        For machine translation, E2D2 is able to match or outperform our diffusion baselines while achieving higher throughput. Compared to MDLM, which does not support exact KV caching, E2D2 offers better downstream task performance with ∼3× faster inference. As shown below, E2D2 achieves higher throughput and task performance relative to the 16-layer BD3LM. While a small 12-layer BD3LM approaches the throughput of E2D2, its BLEU score worsens further.
      </p>

      <table style="width:70%; border-collapse:collapse; font-size:16px; padding:2em;">
      <thead>
        <tr style="background-color:#f2f2f2;">
          <th>Model</th>
          <th>N</th>
          <th>Tput (↑)</th>
          <th>BLEU (↑)</th>
        </tr>
      </thead>
      <tbody>
        <tr><td>AR</td><td>32</td><td>77.6 ± 0.4</td><td><b>25.2</b></td></tr>
        <tr><td>MDLM</td><td>32</td><td>60.4 ± 0.8</td><td>18.4</td></tr>
        <tr><td>BD3LM</td><td>12</td><td>129.6 ± 0.7</td><td>23.3</td></tr>
        <tr><td>BD3LM</td><td>16</td><td>102.4 ± 0.5</td><td>24.0</td></tr>
        <tr><td>E2D2 (Ours)</td><td>28/4</td><td><b>162.0 ± 1.4</b></td><td><b>24.8</b></td></tr>
      </tbody>
        <caption style="caption-side:bottom; padding:1em;">
        <i>WMT (de-en) test BLEU score. Best values for our trained models are <b>bolded</b>.</i>
      </caption>
    </table>
    <p>As above, E2D2 shows improved downstream performance on mathematical reasoning and decoding throughput compared to diffusion baselines.</p>

    <table style="width:90%; border-collapse:collapse; font-size:16px;">
  <caption style="caption-side:bottom; padding:8px;">
    <i>Evaluation on GSM8K test set. Best diffusion value is <b>bolded</b>.</i>
  </caption>
  <thead>
    <tr style="background-color:#f2f2f2;">
      <th>Model</th>
      <th>N</th>
      <th>PPL (↓)</th>
      <th>0-shot pass@1 (↑)</th>
      <th>Tput (↑)</th>
    </tr>
  </thead>
  <tbody>
    <tr><td>AR</td><td>28</td><td>1.49</td><td>66.6</td><td>94.1 ± 0.5</td></tr>
    <tr><td>MDLM</td><td>28</td><td>≤ 2.30</td><td>14.0</td><td>31.9 ± 3.0</td></tr>
    <tr><td>BD3LM</td><td>21</td><td>≤ 1.87</td><td>33.2</td><td>86.6 ± 0.5</td></tr>
    <tr><td>E2D2 (Ours)</td><td>28/14</td><td><b>≤1.80</b></td><td><b>47.9</b></td><td><b>102.8 ± 0.6</b></td></tr>
  </tbody>
</table>
        

    </div>
  </div>
</section>


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
@inproceedings{
  arriola2025e2d2,
  title={Encoder-Decoder Diffusion Language Models for Efficient Training and Inference},
  author={Marianne Arriola and Yair Schiff and Hao Phung and Aaron Gokaslan and Volodymyr Kuleshov},
  booktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},
  year={2025},
  url={TODO}
}
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>